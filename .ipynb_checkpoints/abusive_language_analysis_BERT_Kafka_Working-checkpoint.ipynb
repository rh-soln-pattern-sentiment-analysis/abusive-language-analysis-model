{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kafka-python in /Users/riteshshah/.local/lib/python3.8/site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/riteshshah/.local/lib/python3.8/site-packages (4.29.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/riteshshah/.local/lib/python3.8/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.6.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/riteshshah/.local/lib/python3.8/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: filelock in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: requests in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/riteshshah/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
      "Requirement already satisfied: fsspec in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (0.7.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/riteshshah/.local/lib/python3.8/site-packages (2.0.1)\n",
      "Requirement already satisfied: jinja2 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from torch) (2.11.2)\n",
      "Requirement already satisfied: filelock in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: sympy in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from torch) (1.6.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/riteshshah/.local/lib/python3.8/site-packages (from torch) (4.6.3)\n",
      "Requirement already satisfied: networkx in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from torch) (2.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from sympy->torch) (1.1.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/virat/opt/anaconda3/lib/python3.8/site-packages (from networkx->torch) (4.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.consumer import KafkaConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.producer import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka.errors import KafkaError\n",
    "from transformers import pipeline\n",
    "import ssl\n",
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from ssl import SSLContext, PROTOCOL_TLSv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering for loop\n",
      "ConsumerRecord(topic='consume-topic', partition=0, offset=0, timestamp=1686215790506, timestamp_type=0, key=None, value={'product_id': '3423499', 'user': {'name': 'Rose Gold', 'customer_id': 'rgold', 'browser': 'Chrome', 'region': 'India'}, 'rating': 0, 'timestamp': '168611302302', 'review_text': 'Great spot to grab a cup of coffee and watch the hustle of the city. Staff is not the best nor friendliest/customer service oriented. They were busy but they definitely need someone to clean tables and spot clean throughout the day. Decor gives a fun vibe. Better than the larger chain coffee spots.'}, headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=464, serialized_header_size=-1)\n",
      "Review Text Message BEING PRINTED\n",
      "Great spot to grab a cup of coffee and watch the hustle of the city. Staff is not the best nor friendliest/customer service oriented. They were busy but they definitely need someone to clean tables and spot clean throughout the day. Decor gives a fun vibe. Better than the larger chain coffee spots.\n",
      "ConsumerRecord(topic='consume-topic', partition=0, offset=1, timestamp=1686217005115, timestamp_type=0, key=None, value={'product_id': '3423500', 'user': {'name': 'Rose Silver', 'customer_id': 'rgold', 'browser': 'Chrome', 'region': 'India'}, 'rating': 0, 'timestamp': '168611302302', 'review_text': 'Bad spot to grab a cup of coffee and watch the hustle of the city. Staff is not the best nor friendliest/customer service oriented. They were busy but they definitely need someone to clean tables and spot clean throughout the day. Decor gives a fun vibe. Better than the larger chain coffee spots.'}, headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=464, serialized_header_size=-1)\n",
      "Review Text Message BEING PRINTED\n",
      "Bad spot to grab a cup of coffee and watch the hustle of the city. Staff is not the best nor friendliest/customer service oriented. They were busy but they definitely need someone to clean tables and spot clean throughout the day. Decor gives a fun vibe. Better than the larger chain coffee spots.\n",
      "ConsumerRecord(topic='consume-topic', partition=0, offset=2, timestamp=1686217205486, timestamp_type=0, key=None, value={'product_id': '3423501', 'user': {'name': 'Rose Silver', 'customer_id': 'rgold', 'browser': 'Chrome', 'region': 'India'}, 'rating': 0, 'timestamp': '168611302302', 'review_text': 'Staff is not the best nor friendliest/customer service oriented. They were busy but they definitely need someone to clean tables and spot clean throughout the day. Decor gives a fun vibe. Better than the larger chain coffee spots.'}, headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=397, serialized_header_size=-1)\n",
      "Review Text Message BEING PRINTED\n",
      "Staff is not the best nor friendliest/customer service oriented. They were busy but they definitely need someone to clean tables and spot clean throughout the day. Decor gives a fun vibe. Better than the larger chain coffee spots.\n",
      "ConsumerRecord(topic='consume-topic', partition=0, offset=3, timestamp=1686217869751, timestamp_type=0, key=None, value={'product_id': '3423502', 'user': {'name': 'Rose Shine', 'customer_id': 'rshine', 'browser': 'Safari', 'region': 'UK'}, 'rating': 0, 'timestamp': '168611302304', 'review_text': 'Staff is not the best nor friendliest'}, headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=201, serialized_header_size=-1)\n",
      "Review Text Message BEING PRINTED\n",
      "Staff is not the best nor friendliest\n",
      "ConsumerRecord(topic='consume-topic', partition=0, offset=4, timestamp=1686217925404, timestamp_type=0, key=None, value={'product_id': '3423502', 'user': {'name': 'Rose Shine', 'customer_id': 'rshine', 'browser': 'Safari', 'region': 'UK'}, 'rating': 0, 'timestamp': '168611302304', 'review_text': 'Very bad product and service'}, headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=192, serialized_header_size=-1)\n",
      "Review Text Message BEING PRINTED\n",
      "Very bad product and service\n",
      "ConsumerRecord(topic='consume-topic', partition=0, offset=5, timestamp=1686225846714, timestamp_type=0, key=None, value={'product_id': '3423502', 'user': {'name': 'Rose Shine', 'customer_id': 'rshine', 'browser': 'Safari', 'region': 'UK'}, 'rating': 0, 'timestamp': '168611302304', 'review_text': 'Very shitty product and service'}, headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=195, serialized_header_size=-1)\n",
      "Review Text Message BEING PRINTED\n",
      "Very shitty product and service\n",
      "ConsumerRecord(topic='consume-topic', partition=0, offset=6, timestamp=1686225950313, timestamp_type=0, key=None, value={'product_id': '3423502', 'user': {'name': 'Rose Shine', 'customer_id': 'rshine', 'browser': 'Safari', 'region': 'UK'}, 'rating': 0, 'timestamp': '168611302304', 'review_text': 'Very shitty product and service'}, headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=195, serialized_header_size=-1)\n",
      "Review Text Message BEING PRINTED\n",
      "Very shitty product and service\n",
      "ConsumerRecord(topic='consume-topic', partition=0, offset=7, timestamp=1686226004387, timestamp_type=0, key=None, value={'product_id': '3423503', 'user': {'name': 'Jasmine Shine', 'customer_id': 'jshine', 'browser': 'Chrome', 'region': 'US'}, 'rating': 0, 'timestamp': '168611302306', 'review_text': 'Fucked up product and service'}, headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=196, serialized_header_size=-1)\n",
      "Review Text Message BEING PRINTED\n",
      "Fucked up product and service\n"
     ]
    }
   ],
   "source": [
    "#def analyze_sentiment(text):\n",
    "#    classifier = pipeline(\"sentiment-analysis\")\n",
    "#    result = classifier(text)[0]\n",
    "#    return result[\"label\"]\n",
    "\n",
    "#bootstrap_servers = ['globex-ret-cgbv--fs---qsv-ajjig.bf2.kafka.rhcloud.com:443']\n",
    "topic = 'consume-topic'\n",
    "produce_topic = 'produce-topic'\n",
    "bootstrap_servers = ['localhost:9092']\n",
    "#username = '5c8037b6-8d56-4160-8ea5-e6921d1da5fb'\n",
    "#password = 'affyRJrfk2eYJBcQtQDstnVUGcLXA78U'\n",
    "#sasl_mechanism = 'PLAIN'\n",
    "#security_protocol = 'SASL_SSL'\n",
    "\n",
    "consumer = KafkaConsumer(\n",
    "    topic,\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    auto_offset_reset='earliest',\n",
    "    enable_auto_commit=True,\n",
    "    value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n",
    ")\n",
    "\n",
    "# Set up a Kafka consumer\n",
    "#consumer = KafkaConsumer(\n",
    "#    topic,\n",
    "#    bootstrap_servers=bootstrap_servers,\n",
    "#    sasl_plain_username=username,\n",
    "#    sasl_plain_password=password,\n",
    "#    security_protocol=security_protocol,\n",
    "#    sasl_mechanism=sasl_mechanism,\n",
    "#    auto_offset_reset='latest',\n",
    "#    enable_auto_commit=True,\n",
    "#    value_deserializer=lambda m: json.loads(m.decode('utf-8'))\n",
    "#)\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=bootstrap_servers,\n",
    "    value_serializer=lambda m: json.dumps(m).encode('utf-8')\n",
    ")\n",
    "\n",
    "# Set up a Kafka producer\n",
    "#producer = KafkaProducer(\n",
    "#    bootstrap_servers=bootstrap_servers,\n",
    "#    sasl_plain_username=username,\n",
    "#    sasl_plain_password=password,\n",
    "#    security_protocol=security_protocol,\n",
    "#    sasl_mechanism=sasl_mechanism,\n",
    "#    value_serializer=lambda m: json.dumps(m).encode('utf-8')\n",
    "#)\n",
    "\n",
    "# Load the BERT model and tokenizer\n",
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Load the BERT model and tokenizer\n",
    "model_name = 'Hate-speech-CNERG/english-abusive-MuRIL'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Entering for loop\")\n",
    "# Start consuming Kafka messages\n",
    "for message in consumer:\n",
    "    try:    \n",
    "        # Get the text message from the Kafka message\n",
    "        print(message)\n",
    "        sentiment_data = message.value\n",
    "        product_id = sentiment_data[\"product_id\"]\n",
    "#        customer_id = sentiment_data[\"user\"][\"customer_id\"]\n",
    "        browser = sentiment_data[\"user\"][\"browser\"]\n",
    "        region = sentiment_data[\"user\"][\"region\"]\n",
    "        review_text = sentiment_data[\"review_text\"]\n",
    "        #print(\"Review Text Message BEING PRINTED\")\n",
    "        #print(review_text)   \n",
    "        inputs = tokenizer(review_text, padding=True, truncation=True, max_length=512, return_tensors='pt')\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # Use the BERT model to predict the text being abusive and if yes, then send that to another kafka topic for moderation\n",
    "        outputs = model(**inputs)\n",
    "        #print(outputs)\n",
    "        predictions = torch.softmax(outputs.logits, dim=1).detach().cpu().numpy()\n",
    "        sentiment = int(predictions.argmax(axis=1)[0]) - 1  # Convert 0-4 to -1-3\n",
    "        #print(sentiment)\n",
    "        data = {}\n",
    "        data['sentiment'] = sentiment\n",
    "        data['review_text'] = review_text\n",
    "        response = f\"{'Non-Abusive' if sentiment < 0 else 'Abusive'}\"\n",
    "        data['response'] = response    \n",
    "        json_data = json.dumps(data)\n",
    "        # sentiment_output = f\"{customer_id},{product_id},{sentiment}\" \n",
    "        # Produce a response message with the sentiment\n",
    "        response_message = f\"{product_id}, {review_text} ({'Non-Abusive' if sentiment < 0 else 'Abusive'})\"\n",
    "        if sentiment == 0:\n",
    "            json_string = json.dumps({'sentiment': sentiment, 'product_id': product_id, 'browser': browser, 'region': region, 'review_text': review_text, 'response': response})\n",
    "            producer.send(produce_topic, json_string)\n",
    "        else:\n",
    "            json_string = json.dumps({'sentiment': sentiment, 'product_id': product_id, 'browser': browser, 'region': region, 'review_text': review_text, 'response': response})        \n",
    "            producer.send(produce_topic, json_string)   \n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Non-JSON message received, skipping...\")\n",
    "    except KeyError:\n",
    "        print(\"Missing fields in JSON message, skipping...\")        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
